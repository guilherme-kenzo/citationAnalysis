#!/usr/bin/env python3

import textract
import re
from sys import argv
from nltk.data import load
from nltk.corpus import stopwords

class PdfText(object):

    def __init__(self, pdfFile):
        self.text = ""
        self.sentTokens = ""
        self.sentTokensNoStopWords = []
        self.fileName = ""
        self.citations = []
        self.pageList = []
        self.getText(pdfFile)
        self.splitToList()
        self.nPages = ""
        self.ngrams = []


    def getText(self, pdfFile):
        try:
            self.text = textract.process(pdfFile).decode('utf-8').lower()
            return self.text

        except textract.exceptions.MissingFileError as e:
            raise e
        
    def removeStopWords(self, sentences):
        """Remove stopWords from a given list of sentences"""
        stopWords = stopwords.words('portuguese')
        newList = []
        for i in sentences:
            for j in stopWords:
                i = i.replace(j, '')
            newList.append(i)
        return newList
        
    def tokenizer(self):
        sentTokenizer = load('tokenizers/punkt/portuguese.pickle')
        self.sentTokens = sentTokenizer.tokenize(self.text)
        self.sentTokensNoStopWords = removeStopWords(self.sentTokens)


    def splitToList(self):
        self.pageList = re.split('PÃ¡gina +\d+ +de +\d+', self.text)
        self.nPages = len(self.pageList)
        return self.pageList


    def getMinistros(self):
        listOfMatches = []
        for i in self.pageList:
            matchedMinistros = re.findall('(?<=Ministro |Ministra )\w+',
                                          self.text)
            for j in matchedMinistros:
                listOfMatches.append(j)

        return listOfMatches

if __name__ == '__main__':
    obj = PdfText('ITA.pdf')
    print(obj.getMinistros())
    
